{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение принадлежности текстов к заданной тематике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно определять схожесть текста вакансии с заданной тематикой.\n",
    "\n",
    "Имея набор текстов определенной базовой тематики и набор текстов неизвестной тематики определить, относятся ли тексты к заданной тематике или нет. Предложен список id текстов (test_***.txt текстов), по которым нужно подготовить ответ.\n",
    "\n",
    "Схожесть вакансий может использоваться в рамках content-based рекомендательной системы.\n",
    "\n",
    "Файлы двух типов:\n",
    "\n",
    "файлы base_*.txt - файлы с текстом одинаковой заданной тематики;  \n",
    "файлы test_*.txt - файлы с текстом неизвестной тематики.\n",
    "\n",
    "Содержимым всех файлов является текст (описание вакансии), содержащий html-теги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pymorphy2\n",
    "from tqdm.auto import tqdm\n",
    "from nltk.corpus import words, stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cчитывание base  и test файлов в отдельные датафреймы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_input = '/Users/loban/Projects/Newprolab/ml/lab04/lab04data/base*.txt'\n",
    "files = glob.glob(dir_input)\n",
    "base_df = pd.concat([pd.read_csv(f,header=None,sep='\\t') for f in files],ignore_index=True)\n",
    "\n",
    "bases_index = []\n",
    "\n",
    "for file in files:\n",
    "    temp = str(file.split(\"\\\\\")[1].split('.')[0])\n",
    "    bases_index.append(temp)\n",
    "    \n",
    "base_df.index = bases_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_input = '/Users/loban/Projects/Newprolab/ml/lab04/lab04data/test*.txt'\n",
    "files = glob.glob(dir_input)\n",
    "test_df = pd.concat([pd.read_csv(f,header=None,sep='\\t') for f in files],ignore_index=True)\n",
    "\n",
    "test_index = []\n",
    "\n",
    "for file in files:\n",
    "    temp = str(file.split(\"\\\\\")[1].split('.')[0])\n",
    "    test_index.append(temp)\n",
    "    \n",
    "test_df.index = test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовые + бейз тексты вакансий\n",
    "\n",
    "all_df = pd.concat([test_df, base_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;В наши магазины приходят за красивы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_10</th>\n",
       "      <td>&lt;p&gt;АО «ПанКлуб», представляющий всемирно призн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_100</th>\n",
       "      <td>&lt;p&gt;Что нужно энергичным людям? Интересная, выс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1000</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Требования:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;П...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1001</th>\n",
       "      <td>&lt;p&gt;Что нужно энергичным людям? Интересная, выс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0\n",
       "test_1     <p><strong>В наши магазины приходят за красивы...\n",
       "test_10    <p>АО «ПанКлуб», представляющий всемирно призн...\n",
       "test_100   <p>Что нужно энергичным людям? Интересная, выс...\n",
       "test_1000  <p><strong>Требования:</strong></p> <ul> <li>П...\n",
       "test_1001  <p>Что нужно энергичным людям? Интересная, выс..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание функции для обработки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_only(text):\n",
    "    text = BeautifulSoup(text).get_text()      \n",
    "    words = re.sub(\"[^а-яА-яa-zA-z]\", \" \", text).lower().split()                                \n",
    "    stopw = set(stopwords.words(\"russian\"))                  \n",
    "    cleaned_words = [w for w in words if not w in stopw]  \n",
    "    return(\" \".join(cleaned_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доп.предобработка - создание лемматайзера\n",
    "\n",
    "mystem = Mystem() \n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    text = \" \".join(tokens)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_count = all_df[0].size\n",
    "clean_texts = []\n",
    "\n",
    "for i in range(0, texts_count):\n",
    "    clean_texts.append(words_only(all_df[0][i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1077c587bc497b86052580ca23a481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_texts_s2 = []\n",
    "\n",
    "for i in tqdm(clean_texts):\n",
    "    clean_texts_s2.append(preprocess_text(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'наш   магазин   приходить   красивый   удобный   предмет   кухня   столовая   помогать   наш   покупатель   превращать   приготовление   еда   увлекательный   процесс   наш   ожидание   кандидат   готовность   зарабатывать   понимание   ключевой   показатель   эффективность   продажа   коммуникабельность   позитивность   обучаемость   быстрота   интерес   кулинария   предлагать   стабильный   оклад   плюс   возможность   зарабатывать   высокий   премия   бонус   продажа   удобный   график   работа   плавать   выходной   дополнительный   привилегия   тот   долго   мы   работать   возможность   работать   самый   хороший   оригинальный   товар   кухня   столовая   работа   магазин   уникальный   атмосфера   возможность   развиваться   делать   карьера \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_texts_s2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание векторизированного датафрейма каждого текста с помощью CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=None, preprocessor=None, \n",
    "                             stop_words=None, max_features=20000) \n",
    "\n",
    "sparse_matrix = vectorizer.fit_transform(clean_texts_s2)\n",
    "\n",
    "cleaned_matrix = sparse_matrix.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = cleaned_matrix[:-20]\n",
    "bases = cleaned_matrix[-20:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет косинусной меры сходства обработанных векторов (мера сходства)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765dbcc4255c495fba6e65372c620d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3960.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Мера рассчитывается как сходства каждого тестового текста с 20-ю базовыми текстами и далее суммируется\n",
    "\n",
    "res_df = pd.DataFrame(columns=['CosMetric'])\n",
    "\n",
    "for i in tqdm(range(len(tests))):\n",
    "    our_sum = 0\n",
    "    for k in range(len(bases)):\n",
    "        our_sum += cosine_similarity(tests[i], bases[k]).sum()\n",
    "    res_df.loc[i, 'CosMetric'] = our_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.index = test_df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6777702798498595"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Среднее значение меры, которое далее берется как порог - относится ли текст к заданной тематике или нет\n",
    "\n",
    "mean_cos = res_df['CosMetric'].mean()\n",
    "mean_cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['Our'] = [1 if i > mean_cos else 0 for i in res_df['CosMetric']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2078\n",
       "1    1882\n",
       "Name: Our, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df['Our'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CosMetric</th>\n",
       "      <th>Our</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>1.82601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_10</th>\n",
       "      <td>3.82153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_100</th>\n",
       "      <td>3.70986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1000</th>\n",
       "      <td>3.69877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1001</th>\n",
       "      <td>3.75377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CosMetric  Our\n",
       "test_1      1.82601    0\n",
       "test_10     3.82153    1\n",
       "test_100    3.70986    1\n",
       "test_1000   3.69877    1\n",
       "test_1001   3.75377    1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Id текстов для валидации результатов (вариант 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_ids = [3078.0, 9.0, 3085.0, 2062.0, 1638.0, 3090.0, 533.0, 534.0, 3607.0, 24.0, 538.0, 30.0, 2225.0,\n",
    "           3626.0, 46.0, 1074.0, 2100.0, 3639.0, 56.0, 2901.0, 570.0, 2622.0, 3649.0, 3340.0, 581.0, 1098.0,\n",
    "           2635.0, 1806.0, 1111.0, 89.0, 357.0, 1115.0, 1117.0, 607.0, 358.0, 1634.0, 1126.0, 3178.0, 1131.0,\n",
    "           2668.0, 110.0, 1647.0, 1214.0, 1137.0, 1653.0, 2167.0, 1113.0, 3892.0, 22.0, 3713.0, 3180.0, 645.0,\n",
    "           646.0, 3719.0, 2184.0, 536.0, 658.0, 2708.0, 3183.0, 2199.0, 2712.0, 3738.0, 3739.0, 1692.0, 1695.0, \n",
    "           160.0, 3745.0, 1188.0, 1704.0, 684.0, 174.0, 1711.0, 3102.0, 1201.0, 1714.0, 1831.0, 2230.0, 2744.0,\n",
    "           1726.0, 1215.0, 945.0, 3703.0, 3783.0, 3784.0, 1741.0, 1230.0, 720.0, 1747.0, 213.0, 2682.0, 2265.0, \n",
    "           3292.0, 742.0, 1767.0, 3818.0, 723.0, 2799.0, 3824.0, 1779.0, 1441.0, 3829.0, 758.0, 3831.0, 3712.0,\n",
    "           1277.0, 1281.0, 771.0, 262.0, 3850.0, 2316.0, 1294.0, 783.0, 273.0, 274.0, 791.0, 133.0, 3357.0, 1827.0,\n",
    "           1316.0, 2343.0, 3368.0, 2860.0, 2355.0, 820.0, 2869.0, 311.0, 1849.0, 2688.0, 2878.0, 3904.0, 835.0, 3212.0,\n",
    "           2885.0, 2374.0, 3913.0, 1361.0, 2386.0, 3925.0, 1594.0, 861.0, 2398.0, 2876.0, 3429.0, 2918.0, 2921.0, 2411.0,\n",
    "           3184.0, 1524.0, 3959.0, 1406.0, 383.0, 1174.0, 897.0, 2438.0, 1418.0, 1054.0, 1347.0, 399.0, 1006.0, 1425.0, \n",
    "           1860.0, 3481.0, 1437.0, 2462.0, 1439.0, 2464.0, 2977.0, 1180.0, 1958.0, 2984.0, 943.0, 2481.0, 3508.0, 2485.0,\n",
    "           2634.0, 1469.0, 3007.0, 161.0, 2812.0, 3530.0, 462.0, 3538.0, 468.0, 3030.0, 3547.0, 2526.0, 2531.0, 484.0,\n",
    "           486.0, 2028.0, 2030.0, 498.0, 2548.0, 1013.0, 1586.0, 870.0, 2389.0, 1024.0, 2582.0, 2560.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_ids = ['test_'+ str(int(i)) for i in our_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df[res_df.index.isin(our_ids)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сабмит результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined = []\n",
    "for i in res_df[res_df['Our'] == 1].index.values:\n",
    "    defined.append(int(i.split('_')[1]))\n",
    "    \n",
    "other = []\n",
    "for i in res_df[res_df['Our'] == 0].index.values:\n",
    "    other.append(int(i.split('_')[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined = sorted(defined)\n",
    "other = sorted(other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = {}\n",
    "\n",
    "submit['defined'] = defined\n",
    "submit['other'] = other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lab04.json', 'w') as file:\n",
    "    json.dump(submit, file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
